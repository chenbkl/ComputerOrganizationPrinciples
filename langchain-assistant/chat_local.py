
from langchain_community.llms import Ollama
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹
llm = Ollama(model="llama3", temperature=0.7)

# åˆå§‹åŒ–è®°å¿†
memory = ConversationBufferMemory()

# åˆ›å»ºå¯¹è¯é“¾
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=False
)

# ç®€æ˜“å¯¹è¯
print("ğŸ¤– æœ¬åœ° LLM åŠ©æ‰‹ï¼Œè¾“å…¥ exit é€€å‡º")
while True:
    user_input = input("ä½ ï¼š")
    if user_input.lower() in ['exit', 'quit']:
        break
    response = conversation.run(user_input)
    print("åŠ©æ‰‹ï¼š", response)
