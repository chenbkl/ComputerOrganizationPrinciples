from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.llms import Ollama

llm = Ollama(model="llama3")
intent_prompt = PromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»å™¨ã€‚æˆ‘ä»¬ç³»ç»Ÿæ”¯æŒä»¥ä¸‹ä»»åŠ¡ç±»å‹ï¼š
- æ€»ç»“
- æ”¹å†™
- ç¿»è¯‘
è¯·åˆ¤æ–­ä¸‹åˆ—ç”¨æˆ·è¾“å…¥æœ€æ¥è¿‘å“ªä¸ªä»»åŠ¡ç±»å‹ã€‚è¯·åªè¾“å‡ºå¯¹åº”çš„ä»»åŠ¡ç±»å‹ï¼Œä¸è¦è§£é‡Šã€‚
ç”¨æˆ·è¾“å…¥ï¼š{user_input}
ä»»åŠ¡ç±»å‹ï¼š
""")

intent_chain = LLMChain(prompt=intent_prompt,llm=llm)

def classify_intent(user_input:str)->str:
    return intent_chain.run({"user_input": user_input}).strip()

summary_prompt = PromptTemplate.from_template("è¯·ç”¨ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š\n\n{text}")
summary_prompt_chain = LLMChain(prompt=summary_prompt,llm=llm)

rewrite_prompt = PromptTemplate.from_template("è¯·ç”¨æ›´é€šä¿—çš„è¯­è¨€æ”¹å†™ä»¥ä¸‹å†…å®¹ï¼š\n\n{text}")
rewrite_prompt_chain = LLMChain(prompt=rewrite_prompt,llm=llm)

translation_prompt = PromptTemplate.from_template("è¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘æˆè‹±æ–‡ï¼š\n\n{text}")
translation_prompt_chain = LLMChain(prompt=translation_prompt,llm=llm)

def route_task(user_input:str,intent:str)->str:
    if intent == "æ€»ç»“":
        return summary_prompt_chain.run({"text": user_input}).strip()
    elif intent == "æ”¹å†™":
        return rewrite_prompt_chain.run({"text": user_input}).strip()
    elif intent == "ç¿»è¯‘":
        return translation_prompt_chain.run({"text": user_input}).strip()
    else:
        return "æ— æ³•è¯†åˆ«çš„ä»»åŠ¡ç±»å‹"

if __name__ == "__main__":
    print("ğŸ¤– æ™ºèƒ½æ„å›¾è¯†åˆ«è·¯ç”±ç³»ç»Ÿï¼Œè¾“å…¥ exit é€€å‡º")
    while True:
        user_input = input("ä½ ï¼š")
        if user_input.lower() in ['exit', 'quit']:
            break
        intent = classify_intent(user_input)
        print("ç³»ç»Ÿè¯†åˆ«æ„å›¾ï¼š", intent)
        result = route_task(user_input,intent)
        print("è¾“å‡ºç»“æœï¼š", result)