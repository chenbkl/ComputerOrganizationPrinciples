from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA

# æ­¥éª¤ 1ï¼šåŠ è½½æ–‡æ¡£
loader = TextLoader("your_file.txt", encoding="utf-8")
docs = loader.load()

# æ­¥éª¤ 2ï¼šåˆ‡åˆ†æ–‡æ¡£
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

# æ­¥éª¤ 3ï¼šè½¬ä¸ºå‘é‡ï¼ˆç”¨ Ollama æ¨¡å‹ embeddingï¼‰
embedding = OllamaEmbeddings(model="llama3")

# æ­¥éª¤ 4ï¼šå»ºç«‹å‘é‡æ•°æ®åº“
db = Chroma.from_documents(chunks, embedding)

# æ­¥éª¤ 5ï¼šåˆå§‹åŒ–æœ¬åœ°è¯­è¨€æ¨¡å‹
llm = Ollama(model="llama3")

# æ­¥éª¤ 6ï¼šæ„å»º RetrievalQA é“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=db.as_retriever(),
    return_source_documents=True
)

# æ­¥éª¤ 7ï¼šé—®é—®é¢˜
while True:
    query = input("\nâ“ ä½ æƒ³é—®ä»€ä¹ˆï¼Ÿ(è¾“å…¥ exit é€€å‡º)\n> ")
    if query.lower() in ["exit", "quit"]:
        break
    result = qa_chain({"query": query})
    print("\nğŸ§  ç­”æ¡ˆï¼š", result["result"])
    print("\nğŸ“„ æ¥æºç‰‡æ®µï¼š")
    for doc in result["source_documents"]:
        print("-", doc.page_content[:200])